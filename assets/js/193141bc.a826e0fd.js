"use strict";(self.webpackChunksraddhanand=self.webpackChunksraddhanand||[]).push([[2578],{3905:function(e,t,n){n.d(t,{Zo:function(){return c},kt:function(){return d}});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=a.createContext({}),p=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},c=function(e){var t=p(e.components);return a.createElement(l.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),u=p(n),d=r,g=u["".concat(l,".").concat(d)]||u[d]||m[d]||i;return n?a.createElement(g,o(o({ref:t},c),{},{components:n})):a.createElement(g,o({ref:t},c))}));function d(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=n.length,o=new Array(i);o[0]=u;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,o[1]=s;for(var p=2;p<i;p++)o[p]=n[p];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}u.displayName="MDXCreateElement"},9069:function(e,t,n){n.r(t),n.d(t,{assets:function(){return c},contentTitle:function(){return l},default:function(){return d},frontMatter:function(){return s},metadata:function(){return p},toc:function(){return m}});var a=n(7462),r=n(3366),i=(n(7294),n(3905)),o=["components"],s={id:"pega",title:"Pega System",sidebar_position:1},l=void 0,p={unversionedId:"profile/pega",id:"profile/pega",title:"Pega System",description:"Principal Cloud Development Engineer - ML & AI",source:"@site/docs/profile/pega.md",sourceDirName:"profile",slug:"/profile/pega",permalink:"/docs/profile/pega",editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/profile/pega.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{id:"pega",title:"Pega System",sidebar_position:1},sidebar:"profile",next:{title:"Persistent System",permalink:"/docs/profile/persistent"}},c={},m=[{value:"Principal Cloud Development Engineer - ML &amp; AI",id:"principal-cloud-development-engineer---ml--ai",level:3},{value:"Principal System Engineer - Cloud",id:"principal-system-engineer---cloud",level:3},{value:"Automations",id:"automations",level:3}],u={toc:m};function d(e){var t=e.components,n=(0,r.Z)(e,o);return(0,i.kt)("wrapper",(0,a.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h3",{id:"principal-cloud-development-engineer---ml--ai"},"Principal Cloud Development Engineer - ML & AI"),(0,i.kt)("p",null,(0,i.kt)("em",{parentName:"p"},"June-2021 to PRESENT")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Implemented ",(0,i.kt)("strong",{parentName:"li"},"Service mesh")," practices such as  traffic management, security,  deployment, Session Affinity using ",(0,i.kt)("strong",{parentName:"li"},"Istio")),(0,i.kt)("li",{parentName:"ul"},"Managing Kubernetes environment(s) for ",(0,i.kt)("strong",{parentName:"li"},"multi-tenant")," application deployment, upgrade. security, scalability, HA using ",(0,i.kt)("strong",{parentName:"li"},"Terraform, EKS, Helm Charts")),(0,i.kt)("li",{parentName:"ul"},"Implemented ",(0,i.kt)("strong",{parentName:"li"},"Design Patterns")," such as ",(0,i.kt)("strong",{parentName:"li"},"Retry, Circuit breaker, Ratelimit")," using istio & Gloo Edge"),(0,i.kt)("li",{parentName:"ul"},"Implemented ",(0,i.kt)("strong",{parentName:"li"},"Canary Deployment")," using ",(0,i.kt)("strong",{parentName:"li"},"ArgoCD")," in K8S Cluster"),(0,i.kt)("li",{parentName:"ul"},"Implementing the Observability practices (metrics, traces, logging) using ",(0,i.kt)("strong",{parentName:"li"},"prometheus, jaeger, fluentd & newrelic"))),(0,i.kt)("h3",{id:"principal-system-engineer---cloud"},"Principal System Engineer - Cloud"),(0,i.kt)("p",null,(0,i.kt)("em",{parentName:"p"},"Oct-2018 to May-2021")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Design, Develop, deploy and maintain the high available, scalable and reliable microservice architecture"),(0,i.kt)("li",{parentName:"ul"},"Identifying the pain points in the operations and automating the solutions  to ",(0,i.kt)("strong",{parentName:"li"},"reduce the toil")),(0,i.kt)("li",{parentName:"ul"},"Develop automations to decrease the ",(0,i.kt)("strong",{parentName:"li"},"Mean Time To Detect")," and ",(0,i.kt)("strong",{parentName:"li"},"Mean Time to Recovery")),(0,i.kt)("li",{parentName:"ul"},"Design and implement the Event Driven Auto Remediation for critical alerts triggered by ",(0,i.kt)("strong",{parentName:"li"},"datadog")," and Pega APM"),(0,i.kt)("li",{parentName:"ul"},"Design and implement observability practices such as logging, metrics, tracing using open source softwares such as ",(0,i.kt)("strong",{parentName:"li"},"prometheus, grafana, Elasticsearch - Beats")," for microservice architecture"),(0,i.kt)("li",{parentName:"ul"},"Design solutions to measure ",(0,i.kt)("strong",{parentName:"li"},"uptime, availability, cost-optimization, capacity monitoring.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Proactive monitoring")," for a large fleet of cloud resources and reporting them and designing the  solutions to fix the addressed issues."),(0,i.kt)("li",{parentName:"ul"},"Designed and successfully implemented microservice architecture with best suited ",(0,i.kt)("strong",{parentName:"li"},"design patterns for reliable, scalable, secure")," applications in the cloud."),(0,i.kt)("li",{parentName:"ul"},"Developed and deployed container orchestration using ",(0,i.kt)("strong",{parentName:"li"},"terraform, kubernetes, helm charts, kops"),"."),(0,i.kt)("li",{parentName:"ul"},"Developed and managed multiple ",(0,i.kt)("strong",{parentName:"li"},"Dockerfiles, compose files")," for containerized applications.")),(0,i.kt)("h3",{id:"automations"},"Automations"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},(0,i.kt)("em",{parentName:"strong"},"Forensic Analysis:"))," To reduce Mean Time to Detect the system outage, a python package is created to scan a fleet of instance\u2019s cloudwatch logs for the given time window and display html output consisting of  exceptions, timestamp, number of occurrences per instance along with the whole summary of cluster for the affected environment."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},(0,i.kt)("em",{parentName:"strong"},"Stack Health Validation")),": A consolidated status page of the particular client environment is designed using AWS SSM run command, python script  to gather the indicators and health of the customer environment consisting of multiple tiers of instances. "),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},(0,i.kt)("em",{parentName:"strong"},"Database Health")),": SQL statements based on SOP along with postgresql\u2019s psql utility to get the health of the postgres engine running in AWS RDS. It lists out long running queries, top tables by size, number of connections by clients, Vacuum and bloat info, list of schemas, etc.."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},(0,i.kt)("em",{parentName:"strong"},"JVM dump collection & Analysis")),":  A simple utility to get the thread dumps and heap dumps from the tomcat container and then push it to the analyzing tool."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},(0,i.kt)("em",{parentName:"strong"},"SLA and SLI Metrics")),": With the help of different AWS and datadog metrics, measuring the Service Level Availability and Indicators for the month for all clients."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},(0,i.kt)("em",{parentName:"strong"},"Event Driven Auto-Remediation")),": Handling of 3 types of alerts are automated using EDAR principles. The solution uses event source (Datadog/APM), SNS, Lambda, Python REST API and AWS SSM run commands to accomplish the tasks. "),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},(0,i.kt)("em",{parentName:"strong"},"Disk cleanup")),": It cleans the disk space usage in the ec2 instances."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},(0,i.kt)("em",{parentName:"strong"},"JVM OutOfMemory & Memory Analysis")),": It collects the heap dump, remediates the JVM, analyzes the heap dump and notifies over the Webex Chat."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},(0,i.kt)("em",{parentName:"strong"},"Kafka Offline Partitions or URP")),": It identifies the kafka broker which has offline partitions or under replicated partitions and recovers the service."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},(0,i.kt)("em",{parentName:"strong"},"Time Series metrics")),": Created kubernetes cronjob to run the python script (uses boto3 + Pandas) to collect the metrics using DB query from ~2000 RDS instances, feeds the output csv  into InfluxDB. Grafana dashboards are created to display these metrics.")))}d.isMDXComponent=!0}}]);